% CREATED BY DAVID FRISK, 2014
\chapter{Introduction}
Cloud computing is an abstraction implying the possibility to store data and execute arbitrary code concurrently and with redundancy. The solutions for cloud computing available today are expensive, centralized, and as shown by recent events, susceptible to third-party interference. Such as Distributed Denial of Service (DDoS) attacks or espionage by the National Security Agency or other similar agencies. With a decentralized solution, hardware costs can be mitigated and the risk of third-parties eavesdropping or interfering lowered or even eliminated.

\section{Background}
Services allowing companies and individuals to purchase cloud computing power and storage from a hosting provider, \emph{e.g.} Amazon and Google, have existed for some time. However, this places the consumer in a position where trust between the two parties is neccessary. Trust that the Service Level Agreement is honored, trust that information is kept secret, trust that when the customer deletes information, the information is actually deleted and not secretly kept stored by the storage provider. Initiatives essentially working in reverse of the above, requesting donations of computation power for scientific purposes have also been around for a while. Examples of these include SETI@home (analysis of radio telescopy) and Folding@home (protein analysis). These are centralized grid computing efforts that have resulted in powerful networks building on voluntary contribution to science. By combining and decentralizing
\begin{inparaenum}[\itshape a\upshape)]
\item the ability to purchase computing power; and
\item the ability for individuals to participate with their computing power,
\end{inparaenum}
we propose that a global marketplace of distributed computation power could be created. Such a marketplace would make it possible to buy, sell or even trade computation power, worldwide, with no trust required between parties.

\section{Purpose}
The purpose of this thesis is to investigate how to distribute work on a network of nodes with no central authority, and how to verify that the work has been executed correctly. The key focus is to conduct research in the field of decentralized applications, and to draft a protocol which supports the ideas and features discovered along the way. An effort should be made to create a reference implementation of the protocol and deploy it on a small scale network. The network must meet the following criteria to be usable:
\begin{description}
\item[Transparent] All transactions in the network should be transparent and traceable to show that the system is fair. To achieve this, ledgers must be persistent and auditable.
\item[Resilient] The network must be resistant to attacks from internal and external actors. Such attacks could include disruption of access to the network (DDoS) and attacks that seek to compromise the integrity of ledgers and sabotage the infrastructure of the network.
\item[Trustless] Users of the platforms should not need to trust each other about the details of their agreement when interacting with each other. This will be abstracted away into deterministic code.
\end{description}

\section{Problem}
The overall problem can be summed up as follows: designing a network that lets a client pay to perform work, distributes the work, and pays the workers for their contributions. This problem involves a number of challenges in both security and network communication. However, the challenges can be divided into different subproblems which are easier to solve. Refer to the Vocabulary definitions of \emph{client}, \emph{work}, and \emph{worker} for the next sections. \textbf{TODO: definiera client, worker etc h√§r}
We address the following three issues:
\begin{itemize}
\item Distribution of work
\item Verification of work
\item Monetary compensation to workers
\end{itemize}

\subsection{Distribution of work}
A client that wants work done must have a way of finding workers. This is traditionally done using a centralized server that keeps a record of all workers and their identities \cite{anderson:2005}\cite{sarmenta:2002}. For obvious reasons such a method could not be used in a decentralized network \cite{baran}. Therefore, there must be a way to store this information in a non central location. Furthermore a uniform way of specifying the work payload is necessary to ensure interface compatibility between client and workers. There must also be a way to decide which worker(s) to send the work of a client to. This must be done in a way that ensures all work is distributed somewhat equally throughout the network. Here requirements from the worker has to be taken into consideration. As soon as a worker receives work, it must be executed at some point in the future, implementing weak fairness. There must be a way to send and receive information about work and its status to and from clients and workers.

\subsection{Verification of work}
There must exist a uniform way of executing work so that all involved parties agree on what work is to be performed. When a worker has started on a task there must be some external checking and verification, which ensures that the worker is executing the work as expected. The reasons for incorrect execution could be incidental (incompetence, hardware or software failure) or intentional (to cheat). The problem is discussed by Chang \textit{et al.} albeit on a lower abstraction level~\cite{chang:2002}. Chang \textit{et al.} argue that a virtual machine must be used to execute work, in order to guarantee the soundness of the completed work across the network.

\textbf{Redundancy as verification.} In distributed computation systems, where tasks are deterministic in nature, some kind of result is expected from participants for each task they have been assigned to. The results from the same task performed by different participants can then be compared against each other for proof-checking. For result verification, SETI@home utilizes multiple workers on the same problem, and then compare their results \cite{korpela:2001}. A solution similar to this cannot be used in our network, since we allow arbitrary code to be executed on workers. The network does not expect any answers from workers, nor is it aware of what kind of application is deployed on a worker node, rendering such an approach useless. In addidtion, the recent discovery of the \emph{P +} $\varepsilon$ attack has made this method of verification moot within a decentralized context \cite{buterin:2015}.

\textbf{Mitigating cheating workers.}
In respect to cheating, \textit{i.e.} workers claiming to have completed work without actually having done so, Yurkewych \textit{et al.} prove that redundancy in P2P computing is only cost effective if and only if cheating clients cannot collude \cite{yurkewych:2005}. Since anonymity is of the essence in our network, the option of centralized identity verification is ruled out. It should be noted that Yurkewych \textit{et al.} assume that it is possible to audit the work of a client. Auditing by external parties could be used if there is a defined way to perform auditing. Sarmenta introduces credibility-based auditing in \cite{sarmenta:2002}.

\subsection{Monetary compensation to workers}
Monetary compensation means cryptocurrency-based payment due to inherent trustlessness in transactions, which we see later. The workers should be paid if and only if they perform work and the validity of that work has been established. The payouts should be made in a way which makes it costly for the worker to cheat. Therefore, combining the payout logic with the validity check on a deeper level could be necessary. This is one of the key aspects of the project as it will make sure that the network is not vulnerable to any attacks by internal actors. If this is not handled correctly, the protocol may end up unusable. (Maybe use the idea of putting money down as security? How do we implement that?) 

\section{Scope}
The scope of the thesis is to create a protocol fulfilling the criteria from 1.2 Purpose, and preferably make a reference implementation of said protocol. It is not within the scope of the project to make any applications or programs intended to be deployed on the resulting platform, other than for testing purposes. The protocol should be seen as an open invitation to others to use and develop upon.

To ensure that computations are run in an expected manner on a remote agent there must be some kind of virtual environment which allows software to run deterministically and hardware-independent. It does not fall within the scope of the thesis to implement such an environment.

The protocol will face plenty of security risks, and it is necessary to find countermeasures to possible attacks. It is not the main purpose of the thesis to find all possible attacks on the protocol.