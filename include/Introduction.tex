\chapter{Introduction}
Cloud computing is an abstraction implying the possibility to store data and execute arbitrary code concurrently and with redundancy. The solutions for cloud computing available today are expensive, centralized, and as shown by recent events~\cite{economist:ddos}\cite{guardian:nsa}, susceptible to third-party interference, \emph{e.g.} Distributed Denial of Service (DDoS) attacks and espionage by the National Security Agency or other similar agencies. With a decentralized solution, hardware costs can be mitigated and the risk of third-parties eavesdropping or interfering could be lowered or even eliminated.

\section{Background}
Services allowing companies and individuals to purchase cloud computing power and storage from a hosting provider, \emph{e.g.} Amazon and Google~\cite{elasticcloud}\cite{appengine}, have existed for some time. However, this places the consumer in a position where trust between the two parties is necessary: trust that the Service Level Agreement is honored; trust that information is kept secret; trust that when the customer deletes information, the information is actually deleted and not secretly kept stored by the storage provider.

Initiatives essentially working in reverse of the above, requesting donations of computation power for scientific purposes have also been around for a while. Examples of these include SETI@home (analysis of radio telescope data) and Folding@home (protein analysis)~\cite{korpela:2012}. These are centralized grid computing projects that have resulted in powerful networks building on voluntary contribution to science.

By combining and decentralizing
\begin{inparaenum}[\itshape a\upshape)]
\item the ability to purchase computing power; and
\item the ability for individuals to participate with their computing power,
\end{inparaenum}
we propose that a global marketplace of distributed computation power could be created. Such a marketplace would make it possible to buy, sell or even trade computation power, worldwide, with no trust required between parties.

% Skriv om bittkojn

\section{Purpose}
\label{sec:intro:purpose}
The purpose of this thesis is to investigate how to distribute work on a network of nodes with no central authority, and how to verify that the work has been executed correctly. The key focus is to conduct research in the field of decentralized applications, and to draft a protocol that supports the ideas and features discovered along the way. An effort should be made to create a reference implementation of the protocol and deploy it on a small-scale network. The network must meet the following criteria to be usable:

\textbf{Transparency.} All transactions in the network should be transparent and traceable to show that the system is fair. To achieve this, ledgers must be persistent and auditable.

\textbf{Resilience.} The network must be resistant to attacks from internal and external actors. Such attacks could include disruption of access to the network (DDoS) and attacks that seek to compromise the integrity of ledgers and sabotage the infrastructure of the network.

\textbf{Trustlessness.} Users of the platforms should not be required to trust each other about the details of their agreement when interacting with each other. This should be abstracted away into deterministic code.

\section{Problem}
\label{sec:intro:problem}
The overall problem can be summed up as follows: designing a network that lets a client pay to perform work, distributes the work, and pays the workers for their contributions. These are fundamental problems which must be solved in order to fulfill the purpose of the study, and involve a number of challenges in both security and network communication. However, the challenges can be divided into different subproblems that are easier to solve. In this report \emph{client} refers to a user paying to perform work on the cloud platform; \emph{work} refers to some arbitrary piece of software defined by a client and submitted to be run on the cloud platform; and \emph{worker} refers to a cloud platform node which is performing work in exchange of monetary compensation.
We address the following three issues:
\begin{itemize}
\item How can work be distributed in a decentralized network?
\item How can the network verify that workers execute work correctly?
\item How can workers receive payment for performed work?
\end{itemize}

The issues above have so far not been studied in a decentralized context. However, there exists substantial research describing such problems in centralized grid computing infrastructures. To facilitate our research, a theoretical basis has been synthesized using previous studies and reports from the grid computing field.

\subsection{Distribution of work}
\label{sec:prob:distribution}
A client that wishes to have its work executed must have a way of finding workers. This is traditionally done using a centralized server which maintains a record of all workers and their identities~\cite{anderson:2005}\cite{sarmenta:2002}. For obvious reasons such a method could not be used in a decentralized network~\cite{baran}. Therefore, there must be a way to store this information in a non-central location. Furthermore, a uniform way of specifying the work payload is necessary to ensure interface compatibility between clients and workers. There must also be a way to decide which worker(s) that will receive the work. This must be done in a manner that aims for all work to be distributed evenly throughout the network, and requirements from the worker have to be taken into consideration. Whenever a worker receives work, the work must be executed at some point in the future, implementing weak fairness~\cite{benari}. Both clients and workers will be interested in metadata, so there must be a way to send and receive information about work and its status to and from clients and workers.

\subsection{Verification of work}
\label{sec:prob:verification}
There must exist a uniform way of executing work so that all involved parties agree on what work is to be performed. When a worker has started on a task, there must be some external checking and verification ensuring that the worker is executing the work as expected. The reasons for incorrect execution could be incidental (incompetence, hardware or software failure) or intentional (in an attempt to cheat). This problem is discussed by Chang et al. albeit on a lower abstraction level~\cite{chang:2002}. Chang et al. argue that a virtual machine must be used to execute work, in order to guarantee the soundness of the completed work across the network.

\textbf{Redundancy as verification.} In distributed computation systems, where tasks are deterministic in nature, some kind of result is expected from participants for each task they have been assigned. The results from the same task performed by different participants can then be compared against each other for proof-checking. For result verification, SETI@home utilizes multiple workers on the same problem, and then compare their results~\cite{korpela:2001}. A solution similar to this cannot be used in our network, since we allow arbitrary code to be executed on workers. The network does not expect any answers from workers, nor is it aware of what kind of application is deployed on a worker node, rendering such an approach useless. In addition, the recent discovery of the \emph{P +} $\varepsilon$ attack has made this method of verification infeasible in a decentralized context~\cite{buterin:2015}. In this attack, a malicious user offers workers an additional external reward for providing the network an incorrect result.

\textbf{Mitigating cheating workers.}
In respect to cheating, \textit{i.e.} workers claiming to have completed work without actually having done so, Yurkewych et al. prove that redundancy in P2P computing is cost effective if and only if cheating workers cannot collude~\cite{yurkewych:2005}. In a decentralized network, workers could easily create new identities, which makes it hard to know if any two workers collude. It should be noted that Yurkewych et al. assume that it is possible to audit the work of a client. Auditing by external parties could be used if there is a defined way to perform auditing. The notion of credibility-based auditing, which is introduced by Sarmenta~\cite{sarmenta:2002}, would require the overhead of maintaining a list of credible identities, but could indeed be used to solve the issue of workers creating new identities by assigning a credibility reputation to each identity.

\subsection{Monetary compensation to workers}
\label{sec:prob:compensation}
Monetary compensation would in practice mean a cryptocurrency-based payment due to the inherent trustlessness in such transactions, which is elaborated further in section 2.1. Workers in the network should be paid if and only if they perform work and the validity of said work has been established by network consensus. The payment procedure should be conducted in a way which makes it costly for the worker to cheat, thus making it more attractive to participate honestly than to cheat. Therefore, combining the payout logic with the validity check on a deeper level could be necessary. If it is more profitable to participate honestly than to cheat, this will ensure that the network is not vulnerable to attacks by internal actors. On the contrary, if the aforementioned profitability can not be guaranteed, the protocol may end up unusable. While the work is being performed on behalf of a client, the payment must be held in some kind of escrow. This is to ensure that the client can not cheat by withholding payment when the worker has performed the work, and to ensure that the worker can not receive payment before the work has been completed.

\section{Scope}
The scope of the thesis is to create a protocol fulfilling the criteria from \fullref{sec:intro:purpose}, and attempt to make a reference implementation of said protocol. It is not within the scope of the project to make any applications or programs intended to be deployed on the resulting platform, other than for testing purposes. The protocol should be seen as an open invitation for others to use and develop further.

To ensure that computations are run in an expected manner on a remote agent there must be some kind of virtual environment which allows software to run deterministically and hardware-independent. It does not fall within the scope of the thesis to implement such an environment.

The protocol will face plenty of security risks, and it is necessary to find countermeasures to possible attacks. It is not the main purpose of the thesis to find all possible attacks on the protocol.